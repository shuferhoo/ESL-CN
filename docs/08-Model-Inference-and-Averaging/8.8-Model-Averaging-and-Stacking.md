# 8.8 模型平均和堆栈

| 原文   | [The Elements of Statistical Learning](../book/The Elements of Statistical Learning.pdf) |
| ---- | ---------------------------------------- |
| 翻译   | szcf-weiya                               |
| 时间   | 2017-12-31                               |

在8.4节我们根据一种非参贝叶斯分析，将估计器的bootstrap值看成对应参数近似的后验值。从这个角度看，bagged估计(8.51)是后验贝叶斯均值的近似。相反，训练样本估计$\hat f(x)$对应后验的中值。因为后验均值（不是中值）最小化平方误差损失，所以bagging可以经常降低均方误差也不奇怪。

!!! note "Recall"
    $$
    \hat f_{bag}(x)=\frac{1}{B}\sum\limits_{b=1}^B\hat f^{* b}(x)\tag{8.51}
    $$

这里我们更一般地讨论贝叶斯模型平均。对于我们的训练集$\mathbf Z$，我们有一系列备选模型$\cal M_m,m=1,\ldots,M$。这些模型可以是不同参数的同类模型（比如线性回归的子集），或者对于同样任务的不同模型（比如，神经网络和回归树）。

假设$\zeta$是我们关心的某个值，举个例子，在某个固定的特征值$x$的预测值$f(x)$。$\zeta$的后验分布为

$$
Pr(\zeta\mid \mathbf Z)=\sum\limits_{m=1}^MPr(\zeta\mid \cal M_m,\mathbf Z)Pr(\cal M_m\mid \mathbf Z)\tag{8.53}
$$

其中后验均值为

$$
E(\zeta\mid \mathbf Z)=\sum\limits_{m=1}^ME(\zeta\mid \cal M_m,\mathbf Z)Pr(\cal M_m\mid \mathbf Z)\tag{8.54}
$$

这个贝叶斯预测是单个预测的加权，其中权重与每个模型的后验概率成比例。

这种形式导出了一系列模型平均的策略。Committee方法从每个模型的预测中取简单的无加权，本质上就是对每个模型赋予相等的概率。更雄心勃勃地，第7.7节的发展展现了BIC准则可以用来模型的后验概率。这也可以应用到从同一个参数模型不同参数值产生的不同模型的情形中。BIC根据模型拟合的程度以及参数的个数来对每个模型赋予权重。也可以采用全贝叶斯方法。如果每个模型$\cal M_m$有参数$\theta_m$，我们可以写

$$
\begin{align}
Pr(\cal M_m\mid Z)&\propto Pr(\mathbf Z\mid \cal M_m)\\
&\propto Pr(\cal M_m)\cdot \int Pr(\mathbf Z_m\mid \theta_m,\cal M_m)Pr(\theta_m\mid \cal M_m)d\theta_m\tag{8.55}
\end{align}
$$

原则上，可以确定先验$Pr(\theta_m\mid \cal M_m)$，并且根据式(8.55)数值计算后验概念，从而作为模型平均的权重。然而，相比更简单的BIC近似，我们没有看到任何实际的证据来表明值得这样做。

我们怎么从频率的角度来实现模型平均？给定平方损失下的预测值$\hat f_1(x),\hat f_2(x),\ldots, \hat f_M(x)$，我们可以寻找权重$w=(w_1,w_2,\ldots,w_M)$使得

$$
\hat w=\underset{w}{argmin} E_{\cal P}[Y-\sum\limits_{m=1}^Mw_m\hat f_m(x)]^2\tag{8.56}
$$

这里输入值$x$是固定的，数据集$\mathbf Z$（以及目标$Y$）服从$\cal P$分布$N$个观测。解是$Y$在$\hat F(x)^T\equiv [\hat f_1(x), \hat f_2(x), \ldots, \hat f_M(x)]$上的

$$
\hat w=E_{\cal P}[\hat F(x)\hat F(x)^T]^{-1}E_{\cal P}[\hat F(x)Y]\tag{8.57}
$$

现在全回归模型比任意单模型有更小的误差

$$
E_{\cal P}[Y-\sum\limits_{m=1}^M\hat w_m\hat f_m(x)]^2\le E_{\cal P}[Y-\hat f_m(x)]^2\forall m\tag{8.58}
$$

所以在总体水平下，结合模型不会变得更糟。

当然总体线性回归(8.57)不可行，很自然地用在训练集上的线性回归来替换。但是有简单的例子表明这效果并不好。举个例子，如果$\hat f_m(x),m=1,2,...,M$表示从$M$个输入中取$m$个输入的最优自己的预测，则线性回归将会把所有的权重放在最大的模型上面，也就是，$\hat w_M=1,\hat w_m=0,m<M$。问题是通过考虑模型的复杂性（例子中输入的个数$m$）我们并没有将每个模型放在同一水平。

堆栈泛化(Stacked generalization)，或者称为堆栈，是一种做这件事的方式。令$\hat f_m(x)^{-(i)}$ 是采用模型$m$，应用到除去第$i$个训练观测的数据集上得到的$x$处的预测。权重的堆栈估计是通过$y_i$在$\hat f_m^{-i}(x_i),m=1,2,
\ldots,M$上的最小二乘线性回归得到的。具体地，堆栈参数由下式给出

$$
\hat w^{st}=\underset{w}{argmin}\sum\limits_{i=1}^N[y_i-\sum\limits_{m=1}^Mw_m\hat f_m^{-i}(x_i)]^2\tag{8.59}
$$

最终的预测为$\sum_m\hat w_m^{st}\hat f_m(x)$。通过采用交叉验证的预测值$\hat f_m^{-i}(x)$，堆栈避免了对高复杂度的模型赋予不公平的过高权重。更好的结果可以通过约束权重为非负值并且和为1得到。这似乎是个合理的约束如果我们将权重理解为式(8.54)中的后验模型概率，这导出了易处理的二次规划问题。

堆栈法和模型选择通过舍一法交叉验证紧密联系起来（7.10节）。如果我们将(8.59)的最小化限制到只有一个单元有权重而其它为0的权重向量$w$上，这导出了模型选择有最小舍一法交叉验证误差的$\hat m$。与其选择单模型，堆栈法将之与估计的最优权重结合起来。这通常会有更好的预测，但是比只选择$M$个模型中的一个的解释性更差。

堆栈的思想实际上比上面所描述的更一般。可以采用任意学习的方法，不仅仅是线性回归，来结合(8.59)中的模型；这些权重也可以依赖输出位置$x$。用这种方式，学习方法被堆栈到其它方法的上面来给删预测的效果。
